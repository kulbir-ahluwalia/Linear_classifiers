{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7m4lnpBeAG2T",
        "outputId": "3128e965-607a-430a-bb1e-5a336ec8e566"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.array([-1.5, -2, -1, 0.7, 2.3, -1.9])\n",
        "W = np.array([[-3.5, 0, 3.1, 2.4, 1.8, 0.9], [1.7, -3.8, 0, 1.6, 2.3, -3.0], [2.8, 3.1, -2.9, 0, -2.1, -2.5]])\n",
        "b = np.array([1.1, -2.1, -3.0])\n",
        "W_t = np.transpose(W)\n",
        "print(W_t)\n",
        "y = np.dot(x,W_t) + b\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YA6qkE_ZQU2Q",
        "outputId": "a529bc36-ea0f-4540-b436-ebdf53f2268f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-3.5  1.7  2.8]\n",
            " [ 0.  -3.8  3.1]\n",
            " [ 3.1  0.  -2.9]\n",
            " [ 2.4  1.6  0. ]\n",
            " [ 1.8  2.3 -2.1]\n",
            " [ 0.9 -3.  -2.5]]\n",
            "[  7.36  15.06 -10.58]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%autosave 60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "gnP0ZrY2GYgR",
        "outputId": "2b6c5eb6-633c-47d8-cbc6-f57c63dba24c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(60000)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autosaving every 60 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# src = list(files.upload().values())[0]\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/CS444_assignments/CS444/assignment1\")\n",
        "import sys\n",
        "# sys.path.append('/content/drive/My Drive/CS444_assignments/CS444/assignment1/')\n",
        "sys.path.append(\".\")\n"
      ],
      "metadata": {
        "id": "263fel_7S9w_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \n",
        "pwd = !pwd\n",
        "print(\"Current working directory is: \",pwd)\n",
        "!ls \"models\""
      ],
      "metadata": {
        "id": "YduG8LvrAZNR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "82d85355-d6db-48d5-a689-22db0a8c7447"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Assign1_sandbox.ipynb\t      ksa5_mp1_report.gdoc\n",
            " assignment1.zip\t      ks-projects-201801-utf8.csv\n",
            " cifar_net.pth\t\t      models\n",
            " colab_setup.ipynb\t      mushroom\n",
            "'CS 444 Assignment-1.ipynb'   mylib.py\n",
            " data\t\t\t     'Numpy_logistic_reg_CS 444 Assignment-1.ipynb'\n",
            " data_process.py\t      __pycache__\n",
            " fashion-mnist\t\t      pytorch_tutorial.ipynb\n",
            " kaggle\t\t\t      sandbox\n",
            " kaggle_submission.py\t     'Sandbox_Assign1_CS 444.ipynb'\n",
            "Current working directory is:  ['/content/drive/My Drive/CS444_assignments/CS444/assignment1']\n",
            "__init__.py  logistic.py  perceptron.py  __pycache__  softmax.py  svm.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NAFE9jYL-Mq_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e3545979-636d-4c9c-d307-e7a25c463c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# helpful character encoding module\n",
        "import chardet\n",
        "import math\n",
        "\n",
        "from data_process import get_FASHION_data, get_MUSHROOM_data\n",
        "from scipy.spatial import distance\n",
        "# from models import Perceptron, SVM, Softmax, Logistic\n",
        "\n",
        "from models.logistic import *\n",
        "from models.perceptron import *\n",
        "from models.softmax import *\n",
        "from models.svm import *\n",
        "\n",
        "\n",
        "from kaggle_submission import output_submission_csv\n",
        "%matplotlib inline\n",
        "\n",
        "# For auto-reloading external modules\n",
        "# See http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iO6Lp0l7UZJk",
        "outputId": "23866138-a0db-45a2-e9b4-efa5a588802a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQaAwvAp-MrQ"
      },
      "source": [
        "# Loading Fashion-MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmpLI69M-MrV"
      },
      "source": [
        "In the following cells we determine the number of images for each split and load the images.\n",
        "<br /> \n",
        "TRAIN_IMAGES + VAL_IMAGES = (0, 60000]\n",
        ", TEST_IMAGES = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "G9UlPAZX-MrY"
      },
      "outputs": [],
      "source": [
        "# You can change these numbers for experimentation\n",
        "# For submission we will use the default values \n",
        "TRAIN_IMAGES = 50000\n",
        "VAL_IMAGES = 10000\n",
        "normalize = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls "
      ],
      "metadata": {
        "id": "ljfKmn6R14no",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9d771347-eb53-4446-f15b-3747a72e62e7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Assign1_sandbox.ipynb\t      ksa5_mp1_report.gdoc\n",
            " assignment1.zip\t      ks-projects-201801-utf8.csv\n",
            " cifar_net.pth\t\t      models\n",
            " colab_setup.ipynb\t      mushroom\n",
            "'CS 444 Assignment-1.ipynb'   mylib.py\n",
            " data\t\t\t     'Numpy_logistic_reg_CS 444 Assignment-1.ipynb'\n",
            " data_process.py\t      __pycache__\n",
            " fashion-mnist\t\t      pytorch_tutorial.ipynb\n",
            " kaggle\t\t\t      sandbox\n",
            " kaggle_submission.py\t     'Sandbox_Assign1_CS 444.ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "MzQCIukH-Mrb"
      },
      "outputs": [],
      "source": [
        "data = get_FASHION_data(TRAIN_IMAGES, VAL_IMAGES, normalize=normalize)\n",
        "X_train_fashion, y_train_fashion = data['X_train'], data['y_train']\n",
        "X_val_fashion, y_val_fashion = data['X_val'], data['y_val']\n",
        "X_test_fashion, y_test_fashion = data['X_test'], data['y_test']\n",
        "n_class_fashion = len(np.unique(y_test_fashion))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi8pWY6B-Mre"
      },
      "source": [
        "# Loading Mushroom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlXOrIA--Mrg"
      },
      "source": [
        "\n",
        "In the following cells we determine the splitting of the mushroom dataset.\n",
        "<br /> TRAINING + VALIDATION = 0.8, TESTING = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "s3t5T7fe-Mrj"
      },
      "outputs": [],
      "source": [
        "# TRAINING = 0.6 indicates 60% of the data is used as the training dataset.\n",
        "VALIDATION = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wajrnIZq-Mrn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "70d24607-410d-4780-ea0e-0a81bd317d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train samples:  4874\n",
            "Number of val samples:  1625\n",
            "Number of test samples:  1625\n"
          ]
        }
      ],
      "source": [
        "# TRAINING = 0.6 indicates 60% of the data is used as the training dataset.\n",
        "VALIDATION = 0.2\n",
        "data = get_MUSHROOM_data(VALIDATION)\n",
        "X_train_MR, y_train_MR = data['X_train'], data['y_train']\n",
        "X_val_MR, y_val_MR = data['X_val'], data['y_val']\n",
        "X_test_MR, y_test_MR = data['X_test'], data['y_test']\n",
        "n_class_MR = len(np.unique(y_test_MR))\n",
        "\n",
        "print(\"Number of train samples: \", X_train_MR.shape[0])\n",
        "print(\"Number of val samples: \", X_val_MR.shape[0])\n",
        "print(\"Number of test samples: \", X_test_MR.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usw1n8tF-Mrr"
      },
      "source": [
        "### Get Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x903owui-Mrt"
      },
      "source": [
        "This function computes how well your model performs using accuracy as a metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jGCx_nOk-Mru"
      },
      "outputs": [],
      "source": [
        "def get_acc(pred, y_test):\n",
        "    return np.sum(y_test == pred) / len(y_test) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNsbOkBH-Mrv"
      },
      "source": [
        "# Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oje_amRQ-Mrw"
      },
      "source": [
        "Perceptron has 2 hyperparameters that you can experiment with:\n",
        "- **Learning rate** - controls how much we change the current weights of the classifier during each update. We set it at a default value of 0.5, but you should experiment with different values. We recommend changing the learning rate by factors of 10 and observing how the performance of the classifier changes. You should also try adding a **decay** which slowly reduces the learning rate over each epoch.\n",
        "- **Number of Epochs** - An epoch is a complete iterative pass over all of the data in the dataset. During an epoch we predict a label using the classifier and then update the weights of the classifier according to the perceptron update rule for each sample in the training set. You should try different values for the number of training epochs and report your results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqsMSynE-Mry"
      },
      "source": [
        "You will implement the Perceptron classifier in the **models/perceptron.py**\n",
        "\n",
        "The following code: \n",
        "- Creates an instance of the Perceptron classifier class \n",
        "- The train function of the Perceptron class is trained on the training data\n",
        "- We use the predict function to find the training accuracy as well as the testing accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwM8kvF9-Mrz"
      },
      "source": [
        "## Train Perceptron on Fashion-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([1,2,3,7,12,768,2])\n",
        "arr2 = np.arange(7)\n",
        "#print(np.dot(np.transpose(arr),arr2))\n",
        "weight = np.random.rand(2,2)\n",
        "#print(arr.shape, weight.shape)\n",
        "#print(weight)\n",
        "\n",
        "#print(weight)"
      ],
      "metadata": {
        "id": "x1vlfoJk4sme"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, n_class: int, lr: float, epochs: int):\n",
        "        \"\"\"Initialize a new classifier.\n",
        "\n",
        "        Parameters:\n",
        "            n_class: the number of classes\n",
        "            lr: the learning rate\n",
        "            epochs: the number of epochs to train for\n",
        "        \"\"\"\n",
        "        self.w = None\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.n_class = n_class\n",
        "\n",
        "    def train(self, X_train: np.ndarray, y_train: np.ndarray):\n",
        "        \"\"\"Train the classifier.\n",
        "\n",
        "        Use the perceptron update rule as introduced in the Lecture.\n",
        "\n",
        "        Parameters:\n",
        "            X_train: a number array of shape (N, D) containing training data;\n",
        "                N examples with D dimensions\n",
        "            y_train: a numpy array of shape (N,) containing training labels\n",
        "        \"\"\"\n",
        "        N, D = X_train.shape\n",
        "\n",
        "        #self.w = np.random.rand(self.n_class,D)  # create a weight matrix of shape (1,D)\n",
        "        self.w = np.zeros((self.n_class,D))\n",
        "        #print(self.w)\n",
        "        #print(self.w.shape)\n",
        "        #print(y_train[0:20])\n",
        "        for iter in range(self.epochs):\n",
        "          #if iter > 5:\n",
        "          #  self.lr = 0.5\n",
        "          for example_num in range(N):\n",
        "            x = X_train[example_num]\n",
        "            y_label = y_train[example_num]\n",
        "            y_hat_list = np.dot(self.w, x)  # get the dot product of weight and feature\n",
        "            #print(y_label,y_hat_list)\n",
        "            y_hat_max = np.argmax(y_hat_list)\n",
        "\n",
        "            if y_label == y_hat_max:\n",
        "              pass\n",
        "            else:     # update weight\n",
        "              y_yi = y_hat_list[y_label]      # correct label w^T_yi*xi\n",
        "              #y_c = np.argwhere(y_hat_list > y_yi).reshape(1,-1)  # all labels higher than y_yi\n",
        "\n",
        "              coef_x = (self.lr)*x\n",
        "\n",
        "              for class_num in range(self.n_class):\n",
        "                if iter == 0:\n",
        "                  #if class_num == y_label:\n",
        "                  self.w[y_label] = self.w[y_label] + coef_x\n",
        "                  #else:\n",
        "                  self.w[class_num] = self.w[class_num] - coef_x\n",
        "\n",
        "                if y_hat_list[class_num] > y_yi:\n",
        "                  self.w[y_label] = self.w[y_label] + coef_x\n",
        "                  self.w[class_num] = self.w[class_num] - coef_x\n",
        "\n",
        "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Use the trained weights to predict labels for test data points.\n",
        "\n",
        "        Parameters:\n",
        "            X_test: a numpy array of shape (N, D) containing testing data;\n",
        "                N examples with D dimensions\n",
        "\n",
        "        Returns:\n",
        "            predicted labels for the data in X_test; a 1-dimensional array of\n",
        "                length N, where each element is an integer giving the predicted\n",
        "                class.\n",
        "        \"\"\"\n",
        "        N, D = X_test.shape\n",
        "        labels = np.zeros((N))\n",
        "        #print(self.w.shape)\n",
        "        for example_num in range(N):\n",
        "          x = X_test[example_num]\n",
        "          y_hat = np.dot(self.w,x)\n",
        "          labels[example_num] = np.argmax(y_hat)\n",
        "\n",
        "\n",
        "        return labels"
      ],
      "metadata": {
        "id": "-btUHy9y4U3l"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Dmds-Ynn-Mr1"
      },
      "outputs": [],
      "source": [
        "lr = 0.55\n",
        "n_epochs = 10\n",
        "\n",
        "percept_fashion = Perceptron(n_class_fashion, lr, n_epochs)\n",
        "percept_fashion.train(X_train_fashion, y_train_fashion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GYeUYKyi-Mr2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "53a58290-30fc-4b4f-8220-4fa48fda2cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is given by: 82.242000\n"
          ]
        }
      ],
      "source": [
        "pred_percept = percept_fashion.predict(X_train_fashion)\n",
        "print('The training accuracy is given by: %f' % (get_acc(pred_percept, y_train_fashion)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIVsvDQC-Mr3"
      },
      "source": [
        "### Validate Perceptron on Fashion-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6YLGijfs-Mr4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0575b0dc-63a1-4049-de5f-591d3d0b38ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy is given by: 81.630000\n"
          ]
        }
      ],
      "source": [
        "pred_percept = percept_fashion.predict(X_val_fashion)\n",
        "print('The validation accuracy is given by: %f' % (get_acc(pred_percept, y_val_fashion)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-k_yVhl-Mr6"
      },
      "source": [
        "### Test Perceptron on Fashion-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GFsSA87b-Mr6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "12a8065c-c983-4db3-92b7-01997c3fbbd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The testing accuracy is given by: 80.790000\n"
          ]
        }
      ],
      "source": [
        "pred_percept = percept_fashion.predict(X_test_fashion)\n",
        "print('The testing accuracy is given by: %f' % (get_acc(pred_percept, y_test_fashion)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNSL_DTj-Mr7"
      },
      "source": [
        "### Perceptron_Fashion-MNIST Kaggle Submission\n",
        "\n",
        "Once you are satisfied with your solution and test accuracy, output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KrkXqsw0-Mr8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#copy the kaggle.json token into kaggle folder\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle/kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "Oe928DSiV5q3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aMMFkbpoV6G5",
        "outputId": "446769ca-96fa-4bc4-991d-d4fdd7839395"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "# !kaggle datasets list"
      ],
      "metadata": {
        "id": "6QmNj2iCV-Z-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate csv file for submission\n",
        "output_submission_csv('kaggle/perceptron_submission_fashion.csv', percept_fashion.predict(X_test_fashion))\n",
        "\n",
        "import pandas as pd\n",
        "intermediate_dataframe = pd.read_csv(\"kaggle/perceptron_submission_fashion.csv\")\n",
        "intermediate_dataframe.to_csv('kaggle/perceptron_submission_fashion_utf8_encoding.csv', encoding='utf-8', index=False)\n",
        "\n",
        "\n",
        "# # from https://www.kaggle.com/alexisbcook/character-encodings\n",
        "# # look at the first ten thousand bytes to guess the character encoding\n",
        "with open(\"kaggle/perceptron_submission_fashion_utf8_encoding.csv\", 'rb') as rawdata:\n",
        "    result = chardet.detect(rawdata.read(10000))\n",
        "\n",
        "# check what the character encoding might be\n",
        "print(result)\n",
        "\n",
        "\n",
        "\n",
        "# # from https://www.kaggle.com/alexisbcook/character-encodings\n",
        "# # look at the first ten thousand bytes to guess the character encoding\n",
        "# with open(\"kaggle/perceptron_submission_fashion.csv\", 'rb') as rawdata:\n",
        "#     result = chardet.detect(rawdata.read(10000))\n",
        "# # check what the character encoding might be\n",
        "# print(result)\n",
        "\n",
        "# #check top lines\n",
        "# intermediate_dataframe.head()\n",
        "\n",
        "\n",
        "# # intermediate_dataframe.to_csv(\"kaggle/perceptron_submission_fashion_utf8_encoding.csv\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "11477dHTV-tR",
        "outputId": "b390d1dd-b97d-4a41-b202-749a2e939fb0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'encoding': 'ascii', 'confidence': 1.0, 'language': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(\"kaggle/perceptron_submission_fashion.csv\", 'rb') as source_file:\n",
        "#   with open(\"kaggle/perceptron_submission_fashion_utf8_encoding.csv\", 'w+b') as dest_file:\n",
        "#     contents = source_file.read()\n",
        "#     dest_file.write(contents.decode('utf-16-le').encode('utf-8'))"
      ],
      "metadata": {
        "id": "2yUOMOGfV_Az"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#measure the accuracy on the kaggle competition\n",
        "# !kaggle competitions submit -c cs-444-assignment-1-perceptron -f kaggle/perceptron_submission_fashion_utf8_encoding.csv -m \"Message\""
      ],
      "metadata": {
        "id": "5pudtIA-Rg9M"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0WLw6gm-Mr9"
      },
      "source": [
        "## Train Perceptron on Mushroom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "idBPs2YS-Mr-"
      },
      "outputs": [],
      "source": [
        "lr = 0.15\n",
        "n_epochs = 10\n",
        "\n",
        "percept_MR = Perceptron(n_class_MR, lr, n_epochs)\n",
        "percept_MR.train(X_train_MR, y_train_MR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "F66uuOBh-Mr-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "46f2cacc-ca75-4de3-ccbb-1481c955c150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is given by: 94.521953\n"
          ]
        }
      ],
      "source": [
        "pred_percept = percept_MR.predict(X_train_MR)\n",
        "print('The training accuracy is given by: %f' % (get_acc(pred_percept, y_train_MR)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNuLb2Ms-Mr_"
      },
      "source": [
        "### Validate Perceptron on Mushroom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "va1tiGVE-MsA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b4c7d2c0-66e4-44e1-9166-2f850c30242f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy is given by: 94.030769\n"
          ]
        }
      ],
      "source": [
        "pred_percept = percept_MR.predict(X_val_MR)\n",
        "print('The validation accuracy is given by: %f' % (get_acc(pred_percept, y_val_MR)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuGvsPUV-MsB"
      },
      "source": [
        "### Test Perceptron on Mushroom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "0w1F0DKu-MsC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "84d717d1-10fd-47cc-d2c6-89ae08df9a2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The testing accuracy is given by: 94.215385\n"
          ]
        }
      ],
      "source": [
        "pred_percept = percept_MR.predict(X_test_MR)\n",
        "print('The testing accuracy is given by: %f' % (get_acc(pred_percept, y_test_MR)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDGLZ0eH-MsC"
      },
      "source": [
        "# Support Vector Machines (with SGD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnyHRlrK-MsD"
      },
      "source": [
        "Next, you will implement a \"soft margin\" SVM. In this formulation you will maximize the margin between positive and negative training examples and penalize margin violations using a hinge loss.\n",
        "\n",
        "We will optimize the SVM loss using SGD. This means you must compute the loss function with respect to model weights. You will use this gradient to update the model weights.\n",
        "\n",
        "SVM optimized with SGD has 3 hyperparameters that you can experiment with:\n",
        "- **Learning rate** - similar to as defined above in Perceptron, this parameter scales by how much the weights are changed according to the calculated gradient update. \n",
        "- **Epochs** - similar to as defined above in Perceptron.\n",
        "- **Regularization constant** - Hyperparameter to determine the strength of regularization. In this case it is a coefficient on the term which maximizes the margin. You could try different values. The default value is set to 0.05."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4Qbdf-o-MsD"
      },
      "source": [
        "You will implement the SVM using SGD in the **models/svm.py**\n",
        "\n",
        "The following code: \n",
        "- Creates an instance of the SVM classifier class \n",
        "- The train function of the SVM class is trained on the training data\n",
        "- We use the predict function to find the training accuracy as well as the testing accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m0kwBcO-MsE"
      },
      "source": [
        "## Train SVM on Fashion-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_train_fashion\n",
        "Y = y_train_fashion\n",
        "\n",
        "N, D = X.shape\n",
        "#print(shuffle_in_unison(X[0:100], Y[0:100]))\n",
        "batch_size = 100\n",
        "limit = N/batch_size\n",
        "rand_num = np.random.randint(0,10)\n",
        "slice_x = X[rand_num*batch_size:rand_num*batch_size+batch_size]\n",
        "slice_y = Y[rand_num*batch_size:rand_num*batch_size+batch_size]\n",
        "print(slice_x.shape, slice_y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-lyvql5sgr81",
        "outputId": "d358afdd-ff56-4d0e-e008-e282baa6e9f6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 784) (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SVM:\n",
        "    def __init__(self, n_class: int, lr: float, epochs: int, reg_const: float,batch_size:int):\n",
        "        \"\"\"Initialize a new classifier.\n",
        "\n",
        "        Parameters:\n",
        "            n_class: the number of classes\n",
        "            lr: the learning rate\n",
        "            epochs: the number of epochs to train for\n",
        "            reg_const: the regularization constant\n",
        "        \"\"\"\n",
        "        self.w = None  # TODO: change this\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.reg_const = reg_const\n",
        "        self.n_class = n_class\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate_exponent = learning_rate_exponent\n",
        "\n",
        "    def calc_gradient(self, X_train: np.ndarray, y_train: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Calculate gradient of the svm hinge loss.\n",
        "\n",
        "        Inputs have dimension D, there are C classes\n",
        "\n",
        "        Parameters:\n",
        "            X_train: a numpy array of shape (N, D) containing a mini-batch\n",
        "                of data\n",
        "            y_train: a numpy array of shape (N,) containing training labels;\n",
        "                y[i] = c means that X[i] has label c, where 0 <= c < C\n",
        "\n",
        "        Returns:\n",
        "            the gradient with respect to weights w; an array of the same shape\n",
        "                as w\n",
        "        \"\"\"\n",
        "        x = X_train\n",
        "\n",
        "        y_hat_list = self.reg_const + np.dot(self.reg_const + self.w, x)  # get the dot product of weight and feature\n",
        "\n",
        "        return y_hat_list\n",
        "\n",
        "\n",
        "    def train(self, X_train: np.ndarray, y_train: np.ndarray):\n",
        "        \"\"\"Train the classifier.\n",
        "\n",
        "        Hint: operate on mini-batches of data for SGD.\n",
        "\n",
        "        Parameters:\n",
        "            X_train: a numpy array of shape (N, D) containing training data;\n",
        "                N examples with D dimensions\n",
        "            y_train: a numpy array of shape (N,) containing training labels\n",
        "        \"\"\"\n",
        "        N, D = X_train.shape\n",
        "        batch_size = self.batch_size\n",
        "        #self.w = np.random.uniform(low=0.1, high=0.8,size=(N,D))\n",
        "        #self.w = np.zeros((N,D))\n",
        "        self.w = np.random.rand(self.n_class,D)\n",
        "        #print(self.w.shape)\n",
        "\n",
        "        for iter in range(self.epochs):\n",
        "          #if iter > 4:\n",
        "          # self.lr -= iter*self.lr/9\n",
        "          self.lr *= (self.learning_rate_exponent ** iter)\n",
        "          # self.lr = self.lr * math.exp(-1*(self.learning_rate_exponent)*iter)\n",
        "          print(\"lr: \",self.lr)\n",
        "\n",
        "          #if self.lr > 6:\n",
        "          # self.reg_const /= 0.9\n",
        "          print(\"reg constant: \",self.reg_const)\n",
        "\n",
        "          for example_num in range(0,N,batch_size):\n",
        "            # print(\"example_num is: \",example_num)\n",
        "            x = X_train[example_num]\n",
        "            y_label = y_train[example_num]\n",
        "            #print(y_label)\n",
        "            #print(x.shape)\n",
        "            y_hat_list = self.calc_gradient(x,y_label)\n",
        "            y_correct = y_hat_list[y_label]\n",
        "            #print(y_correct)\n",
        "            #break\n",
        "    \n",
        "            for class_num in range(self.n_class):\n",
        "              if y_correct != y_hat_list[class_num]:\n",
        "                if y_correct - y_hat_list[class_num] < 1: \n",
        "                  self.w[y_label] = self.w[y_label] + self.lr*(x)\n",
        "                  self.w[class_num] = self.w[class_num] - self.lr*(x)\n",
        "\n",
        "              self.w[class_num] = (1 - self.lr*(self.reg_const/self.n_class))*self.w[class_num]\n",
        "          print(\"weights are: \",self.w)\n",
        "          print(\"Epoch number finished: \",iter)\n",
        "        return\n",
        "\n",
        "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Use the trained weights to predict labels for test data points.\n",
        "\n",
        "        Parameters:\n",
        "            X_test: a numpy array of shape (N, D) containing testing data;\n",
        "                N examples with D dimensions\n",
        "\n",
        "        Returns:\n",
        "            predicted labels for the data in X_test; a 1-dimensional array of\n",
        "                length N, where each element is an integer giving the predicted\n",
        "                class.\n",
        "        \"\"\"\n",
        "        N, D = X_test.shape\n",
        "        labels = np.zeros(N)\n",
        "\n",
        "        for image_num in range(N):\n",
        "          x = X_test[image_num]\n",
        "          y_hat_list = np.dot(self.w, x)\n",
        "          labels[image_num] = np.argmax(y_hat_list)\n",
        "          if self.n_class == 2:\n",
        "            labels[image_num] = np.where(labels[image_num] == -1, 0, labels[image_num])\n",
        " \n",
        "        return labels"
      ],
      "metadata": {
        "id": "X_TThXIBF8E-"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "cAXeCWKY-MsE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "df35c6c8-cca8-4902-d5fc-1747596c27d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr:  0.005\n",
            "reg constant:  0.3\n",
            "weights are:  [[-6.24314173e-04 -5.55230464e-03 -9.25478590e-02 ... -4.03130853e+00\n",
            "  -1.71707670e+00 -1.04273875e-01]\n",
            " [ 1.75761981e-04 -7.42850615e-03 -1.30564739e-01 ... -8.15411040e-01\n",
            "  -1.73193354e-01 -9.03518050e-02]\n",
            " [-5.32913653e-04  2.59113932e-03 -1.26196347e-01 ...  2.86645575e+00\n",
            "   6.66995134e-01  3.45573275e-01]\n",
            " ...\n",
            " [ 1.59836791e-04  7.00224201e-04  3.77266269e-03 ... -1.09449588e+00\n",
            "  -4.20138668e-01 -1.63202080e-01]\n",
            " [-1.02328190e-03 -3.65098849e-03 -1.90665045e-01 ... -3.28371930e+00\n",
            "  -1.65204458e+00 -2.50097619e-01]\n",
            " [ 2.19986439e-04 -1.50645528e-03  7.88603168e-04 ...  3.65801094e-01\n",
            "   5.00197886e-01  1.38190374e-01]]\n",
            "Epoch number finished:  0\n",
            "lr:  0.001\n",
            "reg constant:  0.3\n",
            "weights are:  [[-2.11695709e-03  4.75492735e-02  1.50281286e-01 ... -1.47442160e+00\n",
            "  -9.62468422e-01 -1.20471538e-01]\n",
            " [ 8.10993028e-05 -5.61367212e-03 -1.05337423e-01 ... -2.77032377e-01\n",
            "   1.80112268e-01 -3.10966246e-02]\n",
            " [-4.10345612e-03 -1.39060549e-03 -3.68545640e-03 ...  1.49557529e+00\n",
            "   5.17994367e-01  3.11472212e-01]\n",
            " ...\n",
            " [ 8.13028206e-05 -6.36291047e-03 -3.99575323e-02 ... -5.64027030e-01\n",
            "  -1.43721384e-01 -7.43967042e-02]\n",
            " [-1.77472265e-03 -7.62150613e-03 -1.71570895e-01 ... -1.41074228e+00\n",
            "  -1.31159529e+00 -2.68969765e-01]\n",
            " [ 8.33980443e-05 -1.29395351e-02 -4.56452113e-02 ... -1.25084191e-01\n",
            "   2.48296318e-01  9.75217681e-02]]\n",
            "Epoch number finished:  1\n",
            "lr:  4.000000000000001e-05\n",
            "reg constant:  0.3\n",
            "weights are:  [[-2.03571467e-03  5.29781655e-02  1.81531398e-01 ... -1.28263133e+00\n",
            "  -9.09117541e-01 -1.20383767e-01]\n",
            " [ 7.63496981e-05 -6.23257175e-03 -1.06006107e-01 ... -2.83722704e-01\n",
            "   1.62062473e-01 -3.35227968e-02]\n",
            " [-3.82941707e-03 -1.02437005e-03  6.07821619e-03 ...  1.49986045e+00\n",
            "   5.41288228e-01  3.12678676e-01]\n",
            " ...\n",
            " [ 7.93124142e-05 -6.99338499e-03 -4.39910774e-02 ... -5.35024471e-01\n",
            "  -1.26848934e-01 -7.13865438e-02]\n",
            " [-2.30428986e-03 -8.54055279e-03 -1.68526411e-01 ... -1.34632878e+00\n",
            "  -1.27189005e+00 -2.65723130e-01]\n",
            " [ 7.86576109e-05 -1.32050038e-02 -4.94378768e-02 ... -1.27535001e-01\n",
            "   2.36723534e-01  9.47738028e-02]]\n",
            "Epoch number finished:  2\n",
            "lr:  3.2000000000000017e-07\n",
            "reg constant:  0.3\n",
            "weights are:  [[-2.03505275e-03  5.30068300e-02  1.81707053e-01 ... -1.28132887e+00\n",
            "  -9.08760405e-01 -1.20393096e-01]\n",
            " [ 7.63314845e-05 -6.22945480e-03 -1.05974114e-01 ... -2.83690771e-01\n",
            "   1.61972053e-01 -3.35407201e-02]\n",
            " [-3.82721916e-03 -1.01912358e-03  6.14129217e-03 ...  1.50050877e+00\n",
            "   5.41664285e-01  3.12687374e-01]\n",
            " ...\n",
            " [ 7.92818386e-05 -6.99861378e-03 -4.40244041e-02 ... -5.34793089e-01\n",
            "  -1.26700099e-01 -7.13686309e-02]\n",
            " [-2.30833073e-03 -8.53696149e-03 -1.68489658e-01 ... -1.34582830e+00\n",
            "  -1.27161190e+00 -2.65694133e-01]\n",
            " [ 7.86097883e-05 -1.32076918e-02 -4.94695132e-02 ... -1.27604521e-01\n",
            "   2.36553919e-01  9.47255848e-02]]\n",
            "Epoch number finished:  3\n",
            "lr:  5.120000000000004e-10\n",
            "reg constant:  0.3\n",
            "weights are:  [[-2.03505170e-03  5.30068758e-02  1.81707331e-01 ... -1.28132682e+00\n",
            "  -9.08759840e-01 -1.20393112e-01]\n",
            " [ 7.63314513e-05 -6.22944984e-03 -1.05974062e-01 ... -2.83690732e-01\n",
            "   1.61971904e-01 -3.35407491e-02]\n",
            " [-3.82721566e-03 -1.01911531e-03  6.14139400e-03 ...  1.50050996e+00\n",
            "   5.41664896e-01  3.12687386e-01]\n",
            " ...\n",
            " [ 7.92817943e-05 -6.99862211e-03 -4.40244572e-02 ... -5.34792706e-01\n",
            "  -1.26699856e-01 -7.13686019e-02]\n",
            " [-2.30833719e-03 -8.53695574e-03 -1.68489600e-01 ... -1.34582750e+00\n",
            "  -1.27161145e+00 -2.65694086e-01]\n",
            " [ 7.86097127e-05 -1.32076961e-02 -4.94695638e-02 ... -1.27604630e-01\n",
            "   2.36553648e-01  9.47255077e-02]]\n",
            "Epoch number finished:  4\n",
            "lr:  1.6384000000000016e-13\n",
            "reg constant:  0.3\n",
            "weights are:  [[-2.03505170e-03  5.30068759e-02  1.81707331e-01 ... -1.28132682e+00\n",
            "  -9.08759840e-01 -1.20393112e-01]\n",
            " [ 7.63314513e-05 -6.22944984e-03 -1.05974062e-01 ... -2.83690732e-01\n",
            "   1.61971904e-01 -3.35407491e-02]\n",
            " [-3.82721566e-03 -1.01911531e-03  6.14139403e-03 ...  1.50050996e+00\n",
            "   5.41664896e-01  3.12687386e-01]\n",
            " ...\n",
            " [ 7.92817943e-05 -6.99862212e-03 -4.40244573e-02 ... -5.34792705e-01\n",
            "  -1.26699856e-01 -7.13686019e-02]\n",
            " [-2.30833719e-03 -8.53695574e-03 -1.68489600e-01 ... -1.34582750e+00\n",
            "  -1.27161145e+00 -2.65694086e-01]\n",
            " [ 7.86097126e-05 -1.32076961e-02 -4.94695638e-02 ... -1.27604630e-01\n",
            "   2.36553648e-01  9.47255077e-02]]\n",
            "Epoch number finished:  5\n",
            "lr:  1.0485760000000015e-17\n",
            "reg constant:  0.3\n",
            "weights are:  [[-2.03505170e-03  5.30068759e-02  1.81707331e-01 ... -1.28132682e+00\n",
            "  -9.08759840e-01 -1.20393112e-01]\n",
            " [ 7.63314513e-05 -6.22944984e-03 -1.05974062e-01 ... -2.83690732e-01\n",
            "   1.61971904e-01 -3.35407491e-02]\n",
            " [-3.82721566e-03 -1.01911531e-03  6.14139403e-03 ...  1.50050996e+00\n",
            "   5.41664896e-01  3.12687386e-01]\n",
            " ...\n",
            " [ 7.92817943e-05 -6.99862212e-03 -4.40244573e-02 ... -5.34792705e-01\n",
            "  -1.26699856e-01 -7.13686019e-02]\n",
            " [-2.30833719e-03 -8.53695574e-03 -1.68489600e-01 ... -1.34582750e+00\n",
            "  -1.27161145e+00 -2.65694086e-01]\n",
            " [ 7.86097126e-05 -1.32076961e-02 -4.94695638e-02 ... -1.27604630e-01\n",
            "   2.36553648e-01  9.47255077e-02]]\n",
            "Epoch number finished:  6\n",
            "lr:  1.3421772800000025e-22\n",
            "reg constant:  0.3\n",
            "weights are:  [[-2.03505170e-03  5.30068759e-02  1.81707331e-01 ... -1.28132682e+00\n",
            "  -9.08759840e-01 -1.20393112e-01]\n",
            " [ 7.63314513e-05 -6.22944984e-03 -1.05974062e-01 ... -2.83690732e-01\n",
            "   1.61971904e-01 -3.35407491e-02]\n",
            " [-3.82721566e-03 -1.01911531e-03  6.14139403e-03 ...  1.50050996e+00\n",
            "   5.41664896e-01  3.12687386e-01]\n",
            " ...\n",
            " [ 7.92817943e-05 -6.99862212e-03 -4.40244573e-02 ... -5.34792705e-01\n",
            "  -1.26699856e-01 -7.13686019e-02]\n",
            " [-2.30833719e-03 -8.53695574e-03 -1.68489600e-01 ... -1.34582750e+00\n",
            "  -1.27161145e+00 -2.65694086e-01]\n",
            " [ 7.86097126e-05 -1.32076961e-02 -4.94695638e-02 ... -1.27604630e-01\n",
            "   2.36553648e-01  9.47255077e-02]]\n",
            "Epoch number finished:  7\n",
            "lr:  3.435973836800008e-28\n",
            "reg constant:  0.3\n",
            "weights are:  [[-2.03505170e-03  5.30068759e-02  1.81707331e-01 ... -1.28132682e+00\n",
            "  -9.08759840e-01 -1.20393112e-01]\n",
            " [ 7.63314513e-05 -6.22944984e-03 -1.05974062e-01 ... -2.83690732e-01\n",
            "   1.61971904e-01 -3.35407491e-02]\n",
            " [-3.82721566e-03 -1.01911531e-03  6.14139403e-03 ...  1.50050996e+00\n",
            "   5.41664896e-01  3.12687386e-01]\n",
            " ...\n",
            " [ 7.92817943e-05 -6.99862212e-03 -4.40244573e-02 ... -5.34792705e-01\n",
            "  -1.26699856e-01 -7.13686019e-02]\n",
            " [-2.30833719e-03 -8.53695574e-03 -1.68489600e-01 ... -1.34582750e+00\n",
            "  -1.27161145e+00 -2.65694086e-01]\n",
            " [ 7.86097126e-05 -1.32076961e-02 -4.94695638e-02 ... -1.27604630e-01\n",
            "   2.36553648e-01  9.47255077e-02]]\n",
            "Epoch number finished:  8\n",
            "lr:  1.7592186044416049e-34\n",
            "reg constant:  0.3\n",
            "weights are:  [[-2.03505170e-03  5.30068759e-02  1.81707331e-01 ... -1.28132682e+00\n",
            "  -9.08759840e-01 -1.20393112e-01]\n",
            " [ 7.63314513e-05 -6.22944984e-03 -1.05974062e-01 ... -2.83690732e-01\n",
            "   1.61971904e-01 -3.35407491e-02]\n",
            " [-3.82721566e-03 -1.01911531e-03  6.14139403e-03 ...  1.50050996e+00\n",
            "   5.41664896e-01  3.12687386e-01]\n",
            " ...\n",
            " [ 7.92817943e-05 -6.99862212e-03 -4.40244573e-02 ... -5.34792705e-01\n",
            "  -1.26699856e-01 -7.13686019e-02]\n",
            " [-2.30833719e-03 -8.53695574e-03 -1.68489600e-01 ... -1.34582750e+00\n",
            "  -1.27161145e+00 -2.65694086e-01]\n",
            " [ 7.86097126e-05 -1.32076961e-02 -4.94695638e-02 ... -1.27604630e-01\n",
            "   2.36553648e-01  9.47255077e-02]]\n",
            "Epoch number finished:  9\n"
          ]
        }
      ],
      "source": [
        "lr = 0.005\n",
        "n_epochs = 10\n",
        "reg_const = 0.3\n",
        "learning_rate_exponent = 0.2\n",
        "batch_size = 1\n",
        "\n",
        "svm_fashion = SVM(n_class_fashion, lr, n_epochs, reg_const,batch_size)\n",
        "svm_fashion.train(X_train_fashion, y_train_fashion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "oTJWUctD-MsF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cfac1d09-9068-43ff-f268-755cd5855f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is given by: 84.134000\n"
          ]
        }
      ],
      "source": [
        "pred_svm = svm_fashion.predict(X_train_fashion)\n",
        "print('The training accuracy is given by: %f' % (get_acc(pred_svm, y_train_fashion)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDdZJ6J3-MsV"
      },
      "source": [
        "### Validate SVM on Fashion-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Be31w3Gh-MsW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "66ccacfb-0b06-496c-8c2e-3491e7e475ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy is given by: 82.730000\n"
          ]
        }
      ],
      "source": [
        "pred_svm = svm_fashion.predict(X_val_fashion)\n",
        "print('The validation accuracy is given by: %f' % (get_acc(pred_svm, y_val_fashion)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13UhK-6E-MsX"
      },
      "source": [
        "### Test SVM on Fashion-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "-h_boSMV-MsY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "89afc465-25b6-4cc2-c6b1-126ec04a599d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The testing accuracy is given by: 81.460000\n"
          ]
        }
      ],
      "source": [
        "pred_svm = svm_fashion.predict(X_test_fashion)\n",
        "print('The testing accuracy is given by: %f' % (get_acc(pred_svm, y_test_fashion)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpPKgYo9-MsZ"
      },
      "source": [
        "### SVM_Fashion-MNIST Kaggle Submission\n",
        "\n",
        "Once you are satisfied with your solution and test accuracy output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "1P4cQcbk-Msa"
      },
      "outputs": [],
      "source": [
        "output_submission_csv('kaggle/svm_submission_fashion.csv', svm_fashion.predict(X_test_fashion))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpChKzUb-Msb"
      },
      "source": [
        "## Train SVM on Mushroom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "UUYAF7u_-Msb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0c1b2904-73de-4495-a292-d4d5cddb848d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr:  0.001\n",
            "reg constant:  0.6\n",
            "weights are:  [[ 0.10878419 -0.03859232  0.11596207  0.16021186  0.1995664   0.16355074\n",
            "   0.20828329 -0.05079235  0.30329904  0.26626704  0.25651566  0.25064784\n",
            "   0.20805044  0.21310121  0.1895454   0.08497318 -0.08924052  0.20692438\n",
            "   0.16721216  0.15434198 -0.15085448  0.08369037]\n",
            " [ 0.14191002  0.12491593  0.14407056  0.01724357  0.12072975  0.0771566\n",
            "  -0.00427552  0.3604911   0.11069229 -0.00788924 -0.04946089 -0.05439747\n",
            "   0.01167976  0.1627856   0.12778503  0.02280364  0.18341235  0.12714202\n",
            "  -0.03623895  0.06669896  0.37081923  0.17711974]]\n",
            "Epoch number finished:  0\n",
            "lr:  0.0002\n",
            "reg constant:  0.6\n",
            "weights are:  [[ 0.07384644 -0.02093321  0.08087334  0.15628873  0.16445622  0.10791656\n",
            "   0.18162225 -0.09496755  0.20829444  0.22261671  0.23560049  0.20941952\n",
            "   0.17474792  0.14751032  0.13028818  0.06342683 -0.09359067  0.16010824\n",
            "   0.14988877  0.12034391 -0.13692341  0.05231206]\n",
            " [ 0.11331193  0.08538558  0.1132677  -0.02382416  0.07466128  0.07176418\n",
            "  -0.02934177  0.32613858  0.10077033 -0.02975006 -0.08103408 -0.06291576\n",
            "  -0.01071789  0.13312009  0.10663342  0.0170214   0.16390131  0.08926028\n",
            "  -0.05209929  0.04467755  0.3011471   0.14237946]]\n",
            "Epoch number finished:  1\n",
            "lr:  8.000000000000001e-06\n",
            "reg constant:  0.6\n",
            "weights are:  [[ 0.07148868 -0.02144935  0.07780958  0.15622254  0.15999468  0.10547143\n",
            "   0.18087828 -0.09690085  0.20565338  0.22096837  0.23497162  0.20706081\n",
            "   0.17277637  0.14277249  0.12453547  0.06268921 -0.0948106   0.15789148\n",
            "   0.14940225  0.11531486 -0.13804657  0.04989713]\n",
            " [ 0.11349321  0.0851522   0.11407379 -0.02529846  0.07634209  0.07211973\n",
            "  -0.03036873  0.3253835   0.09981722 -0.03034464 -0.08220271 -0.06226078\n",
            "  -0.01065389  0.13459444  0.10963096  0.01682345  0.1643036   0.08857704\n",
            "  -0.05274996  0.04778755  0.30036049  0.14253026]]\n",
            "Epoch number finished:  2\n",
            "lr:  6.400000000000003e-08\n",
            "reg constant:  0.6\n",
            "weights are:  [[ 0.07146996 -0.02145182  0.07778477  0.15622079  0.15996428  0.10545209\n",
            "   0.18087268 -0.09691476  0.20562089  0.22095557  0.23496551  0.20704156\n",
            "   0.17275994  0.14273814  0.12449464  0.06268334 -0.0948201   0.15787421\n",
            "   0.14939332  0.11528417 -0.13805701  0.04988184]\n",
            " [ 0.11349462  0.08514871  0.11408065 -0.02530895  0.07635037  0.07212245\n",
            "  -0.03037722  0.32537602  0.09982113 -0.03034968 -0.08221089 -0.06225508\n",
            "  -0.01065264  0.13460284  0.10964989  0.01682187  0.1643066   0.08857125\n",
            "  -0.05275008  0.04780298  0.30035575  0.14252755]]\n",
            "Epoch number finished:  3\n",
            "lr:  1.0240000000000007e-10\n",
            "reg constant:  0.6\n",
            "weights are:  [[ 0.07146993 -0.02145183  0.07778473  0.15622079  0.15996424  0.10545206\n",
            "   0.18087267 -0.09691478  0.20562084  0.22095555  0.2349655   0.20704153\n",
            "   0.17275992  0.14273808  0.12449457  0.06268333 -0.09482011  0.15787418\n",
            "   0.14939331  0.11528412 -0.13805703  0.04988181]\n",
            " [ 0.11349462  0.08514871  0.11408066 -0.02530897  0.07635038  0.07212246\n",
            "  -0.03037723  0.32537601  0.09982113 -0.03034968 -0.08221091 -0.06225507\n",
            "  -0.01065264  0.13460285  0.10964992  0.01682187  0.1643066   0.08857124\n",
            "  -0.05275008  0.047803    0.30035574  0.14252754]]\n",
            "Epoch number finished:  4\n",
            "lr:  3.276800000000003e-14\n",
            "reg constant:  0.6\n",
            "weights are:  [[ 0.07146993 -0.02145183  0.07778473  0.15622079  0.15996424  0.10545206\n",
            "   0.18087267 -0.09691478  0.20562084  0.22095555  0.2349655   0.20704153\n",
            "   0.17275992  0.14273808  0.12449457  0.06268333 -0.09482011  0.15787418\n",
            "   0.14939331  0.11528412 -0.13805703  0.04988181]\n",
            " [ 0.11349462  0.08514871  0.11408066 -0.02530897  0.07635038  0.07212246\n",
            "  -0.03037723  0.32537601  0.09982113 -0.03034968 -0.08221091 -0.06225507\n",
            "  -0.01065264  0.13460285  0.10964992  0.01682187  0.1643066   0.08857124\n",
            "  -0.05275008  0.047803    0.30035574  0.14252754]]\n",
            "Epoch number finished:  5\n",
            "lr:  2.0971520000000025e-18\n",
            "reg constant:  0.6\n",
            "weights are:  [[ 0.07146993 -0.02145183  0.07778473  0.15622079  0.15996424  0.10545206\n",
            "   0.18087267 -0.09691478  0.20562084  0.22095555  0.2349655   0.20704153\n",
            "   0.17275992  0.14273808  0.12449457  0.06268333 -0.09482011  0.15787418\n",
            "   0.14939331  0.11528412 -0.13805703  0.04988181]\n",
            " [ 0.11349462  0.08514871  0.11408066 -0.02530897  0.07635038  0.07212246\n",
            "  -0.03037723  0.32537601  0.09982113 -0.03034968 -0.08221091 -0.06225507\n",
            "  -0.01065264  0.13460285  0.10964992  0.01682187  0.1643066   0.08857124\n",
            "  -0.05275008  0.047803    0.30035574  0.14252754]]\n",
            "Epoch number finished:  6\n",
            "lr:  2.6843545600000043e-23\n",
            "reg constant:  0.6\n",
            "weights are:  [[ 0.07146993 -0.02145183  0.07778473  0.15622079  0.15996424  0.10545206\n",
            "   0.18087267 -0.09691478  0.20562084  0.22095555  0.2349655   0.20704153\n",
            "   0.17275992  0.14273808  0.12449457  0.06268333 -0.09482011  0.15787418\n",
            "   0.14939331  0.11528412 -0.13805703  0.04988181]\n",
            " [ 0.11349462  0.08514871  0.11408066 -0.02530897  0.07635038  0.07212246\n",
            "  -0.03037723  0.32537601  0.09982113 -0.03034968 -0.08221091 -0.06225507\n",
            "  -0.01065264  0.13460285  0.10964992  0.01682187  0.1643066   0.08857124\n",
            "  -0.05275008  0.047803    0.30035574  0.14252754]]\n",
            "Epoch number finished:  7\n",
            "lr:  6.871947673600015e-29\n",
            "reg constant:  0.6\n",
            "weights are:  [[ 0.07146993 -0.02145183  0.07778473  0.15622079  0.15996424  0.10545206\n",
            "   0.18087267 -0.09691478  0.20562084  0.22095555  0.2349655   0.20704153\n",
            "   0.17275992  0.14273808  0.12449457  0.06268333 -0.09482011  0.15787418\n",
            "   0.14939331  0.11528412 -0.13805703  0.04988181]\n",
            " [ 0.11349462  0.08514871  0.11408066 -0.02530897  0.07635038  0.07212246\n",
            "  -0.03037723  0.32537601  0.09982113 -0.03034968 -0.08221091 -0.06225507\n",
            "  -0.01065264  0.13460285  0.10964992  0.01682187  0.1643066   0.08857124\n",
            "  -0.05275008  0.047803    0.30035574  0.14252754]]\n",
            "Epoch number finished:  8\n",
            "lr:  3.5184372088832095e-35\n",
            "reg constant:  0.6\n",
            "weights are:  [[ 0.07146993 -0.02145183  0.07778473  0.15622079  0.15996424  0.10545206\n",
            "   0.18087267 -0.09691478  0.20562084  0.22095555  0.2349655   0.20704153\n",
            "   0.17275992  0.14273808  0.12449457  0.06268333 -0.09482011  0.15787418\n",
            "   0.14939331  0.11528412 -0.13805703  0.04988181]\n",
            " [ 0.11349462  0.08514871  0.11408066 -0.02530897  0.07635038  0.07212246\n",
            "  -0.03037723  0.32537601  0.09982113 -0.03034968 -0.08221091 -0.06225507\n",
            "  -0.01065264  0.13460285  0.10964992  0.01682187  0.1643066   0.08857124\n",
            "  -0.05275008  0.047803    0.30035574  0.14252754]]\n",
            "Epoch number finished:  9\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "n_epochs = 10\n",
        "reg_const = 0.6\n",
        "batch_size = 1\n",
        "\n",
        "svm_MR = SVM(n_class_MR, lr, n_epochs, reg_const,batch_size)\n",
        "svm_MR.train(X_train_MR, y_train_MR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "l4Cat3yi-Msc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "058fe249-0a62-41c0-9b3e-d1f30a2daeb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is given by: 90.069758\n"
          ]
        }
      ],
      "source": [
        "pred_svm = svm_MR.predict(X_train_MR)\n",
        "print('The training accuracy is given by: %f' % (get_acc(pred_svm, y_train_MR)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyBqJx7O-Msc"
      },
      "source": [
        "### Validate SVM on Mushroom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "gMiU7bRE-Msd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5aab9473-efe1-4f08-fd9f-59eec90a6a38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy is given by: 88.800000\n"
          ]
        }
      ],
      "source": [
        "pred_svm = svm_MR.predict(X_val_MR)\n",
        "print('The validation accuracy is given by: %f' % (get_acc(pred_svm, y_val_MR)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2_6-Q58-Msd"
      },
      "source": [
        "## Test SVM on Mushroom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "ItOO6hlg-Msd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fdcba7f7-2978-4e27-833a-f09724048d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The testing accuracy is given by: 88.800000\n"
          ]
        }
      ],
      "source": [
        "pred_svm = svm_MR.predict(X_test_MR)\n",
        "print('The testing accuracy is given by: %f' % (get_acc(pred_svm, y_test_MR)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbeJN_Yn-Mse"
      },
      "source": [
        "# Softmax Classifier (with SGD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "A1IBoNnK-Mse"
      },
      "source": [
        "Next, you will train a Softmax classifier. This classifier consists of a linear function of the input data followed by a softmax function which outputs a vector of dimension C (number of classes) for each data point. Each entry of the softmax output vector corresponds to a confidence in one of the C classes, and like a probability distribution, the entries of the output vector sum to 1. We use a cross-entropy loss on this sotmax output to train the model. \n",
        "\n",
        "Check the following link as an additional resource on softmax classification: http://cs231n.github.io/linear-classify/#softmax\n",
        "\n",
        "Once again we will train the classifier with SGD. This means you need to compute the gradients of the softmax cross-entropy loss function according to the weights and update the weights using this gradient. Check the following link to help with implementing the gradient updates: https://deepnotes.io/softmax-crossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bq72ygY-Msf"
      },
      "source": [
        "The softmax classifier has 3 hyperparameters that you can experiment with:\n",
        "- **Learning rate** - As above, this controls how much the model weights are updated with respect to their gradient.\n",
        "- **Number of Epochs** - As described for perceptron.\n",
        "- **Regularization constant** - Hyperparameter to determine the strength of regularization. In this case, we minimize the L2 norm of the model weights as regularization, so the regularization constant is a coefficient on the L2 norm in the combined cross-entropy and regularization objective."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1Vn3U7k-Msf"
      },
      "source": [
        "You will implement a softmax classifier using SGD in the **models/softmax.py**\n",
        "\n",
        "The following code: \n",
        "- Creates an instance of the Softmax classifier class \n",
        "- The train function of the Softmax class is trained on the training data\n",
        "- We use the predict function to find the training accuracy as well as the testing accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y4W4-_Q-Msg"
      },
      "source": [
        "## Train Softmax on Fashion-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(([-2.85],[0.86],[0.28]))\n",
        "exp_y = np.exp(y)\n",
        "log_k = -np.max(exp_y)\n",
        "exp_y_logk = exp_y + log_k\n",
        "#print(log_k)\n",
        "sum_exp_y = np.sum(exp_y_logk)\n",
        "#print(exp_y_logk)\n",
        "#print(exp_y_logk/sum_exp_y)"
      ],
      "metadata": {
        "id": "pEn6WgR6_AL6"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = np.random.uniform(low=0.01, high=0.1,size=(10,2))\n",
        "#print(z)\n",
        "#print(np.linalg.norm(z))"
      ],
      "metadata": {
        "id": "3jPT9L1S-Zv3"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Softmax model.\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Softmax:\n",
        "    def __init__(self, n_class: int, lr: float, epochs: int, reg_const: float):\n",
        "        \"\"\"Initialize a new classifier.\n",
        "\n",
        "        Parameters:\n",
        "            n_class: the number of classes\n",
        "            lr: the learning rate\n",
        "            epochs: the number of epochs to train for\n",
        "            reg_const: the regularization constant\n",
        "        \"\"\"\n",
        "        self.w = None  # TODO: change this\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.reg_const = reg_const\n",
        "        self.n_class = n_class\n",
        "\n",
        "    def calc_gradient(self, X_train: np.ndarray, y_train: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Calculate gradient of the softmax loss.\n",
        "\n",
        "        Inputs have dimension D, there are C classes, and we operate on\n",
        "        mini-batches of N examples.\n",
        "\n",
        "        Parameters:\n",
        "            X_train: a numpy array of shape (N, D) containing a mini-batch\n",
        "                of data\n",
        "            y_train: a numpy array of shape (N,) containing training labels;\n",
        "                y[i] = c means that X[i] has label c, where 0 <= c < C\n",
        "\n",
        "        Returns:\n",
        "            gradient with respect to weights w; an array of same shape as w\n",
        "        \"\"\"\n",
        "        #N, D = X_train.shape\n",
        "        #print(N,D)\n",
        "        #gradients = np.zeros((N,D))\n",
        "        x = X_train\n",
        "\n",
        "        y_hat_list = np.dot(self.reg_const + self.w, x)  # get the dot product of weight and feature\n",
        "        #print(y_hat_list)\n",
        "        #exp_y = np.exp(y_hat_list)\n",
        "        #print(exp_y)\n",
        "        log_k = -np.max(y_hat_list)\n",
        "        exp_y = np.exp(y_hat_list + log_k)\n",
        "        sum_exp_y = np.sum(exp_y)\n",
        "        gradients = exp_y / sum_exp_y\n",
        "\n",
        "        return gradients\n",
        "\n",
        "    def train(self, X_train: np.ndarray, y_train: np.ndarray):\n",
        "        \"\"\"Train the classifier.\n",
        "\n",
        "        Hint: operate on mini-batches of data for SGD.\n",
        "\n",
        "        Parameters:\n",
        "            X_train: a numpy array of shape (N, D) containing training data;\n",
        "                N examples with D dimensions\n",
        "            y_train: a numpy array of shape (N,) containing training labels\n",
        "        \"\"\"\n",
        "        N, D = X_train.shape\n",
        "        #self.w = np.random.uniform(low=0.1, high=0.8,size=(N,D))\n",
        "        #self.w = np.zeros((N,D))\n",
        "        self.w = np.random.rand(self.n_class,D)\n",
        "        #print(self.w.shape)\n",
        "\n",
        "        for iter in range(self.epochs):\n",
        "          #if iter > 4:\n",
        "          self.lr -= iter*self.lr/5\n",
        "\n",
        "          #if self.lr > 6:\n",
        "          self.reg_const /= 0.9\n",
        "\n",
        "          for example_num in range(N):\n",
        "            x = X_train[example_num]\n",
        "            y_label = y_train[example_num]\n",
        "            #print(y_label)\n",
        "            #print(x.shape)\n",
        "            gradients = self.calc_gradient(x,y_label)\n",
        "            #print(gradients)\n",
        "            #break\n",
        "    \n",
        "            for class_num in range(self.n_class):\n",
        "              if class_num == y_label:\n",
        "                self.w[y_label] = self.w[y_label] + (self.lr*(1 - gradients[y_label]))*x\n",
        "              else:\n",
        "                self.w[class_num] = self.w[class_num] - (self.lr*(gradients[class_num]))*x\n",
        "\n",
        "\n",
        "        return\n",
        "\n",
        "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Use the trained weights to predict labels for test data points.\n",
        "\n",
        "        Parameters:\n",
        "            X_test: a numpy array of shape (N, D) containing testing data;\n",
        "                N examples with D dimensions\n",
        "\n",
        "        Returns:\n",
        "            predicted labels for the data in X_test; a 1-dimensional array of\n",
        "                length N, where each element is an integer giving the predicted\n",
        "                class.\n",
        "        \"\"\"\n",
        "        N, D = X_test.shape\n",
        "        labels = np.zeros(N)\n",
        "\n",
        "        for image_num in range(N):\n",
        "          x = X_test[image_num]\n",
        "          y_hat_list = np.dot(self.w, x)\n",
        "          labels[image_num] = np.argmax(y_hat_list)\n",
        "          if self.n_class == 2:\n",
        "            labels[image_num] = np.where(labels[image_num] == -1, 0, labels[image_num])\n",
        " \n",
        "        return labels"
      ],
      "metadata": {
        "id": "MJgzICTpZ6_D"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "MwCJwItq-Msh"
      },
      "outputs": [],
      "source": [
        "lr = 0.01\n",
        "n_epochs = 14\n",
        "reg_const = 0.55\n",
        "\n",
        "softmax_fashion = Softmax(n_class_fashion, lr, n_epochs, reg_const)\n",
        "softmax_fashion.train(X_train_fashion, y_train_fashion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "-ZQbZyi4-Msh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0b2240cc-2a41-4f29-a259-a5cbc29032c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is given by: 84.976000\n"
          ]
        }
      ],
      "source": [
        "pred_softmax = softmax_fashion.predict(X_train_fashion)\n",
        "print('The training accuracy is given by: %f' % (get_acc(pred_softmax, y_train_fashion)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASvNCdbQ-Msi"
      },
      "source": [
        "### Validate Softmax on Fashion-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "AwXoZoKU-Msj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d0996fe2-6448-41ae-9ebe-b83a0c1d1f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy is given by: 81.580000\n"
          ]
        }
      ],
      "source": [
        "pred_softmax = softmax_fashion.predict(X_val_fashion)\n",
        "print('The validation accuracy is given by: %f' % (get_acc(pred_softmax, y_val_fashion)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUqLKR3T-Msk"
      },
      "source": [
        "### Testing Softmax on Fashion-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "AwAZxSNV-Msk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "02780d5a-9064-49ec-de9f-b1bb5b33f0f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The testing accuracy is given by: 80.640000\n"
          ]
        }
      ],
      "source": [
        "pred_softmax = softmax_fashion.predict(X_test_fashion)\n",
        "print('The testing accuracy is given by: %f' % (get_acc(pred_softmax, y_test_fashion)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29zCFWnI-Msl"
      },
      "source": [
        "### Softmax_Fashion-MNIST Kaggle Submission\n",
        "\n",
        "Once you are satisfied with your solution and test accuracy output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "yW_vi3KD-Msl"
      },
      "outputs": [],
      "source": [
        "output_submission_csv('kaggle/softmax_submission_fashion.csv', softmax_fashion.predict(X_test_fashion))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7uJ_OLw-Msm"
      },
      "source": [
        "## Train Softmax on Mushroom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "4uBincW0-Msm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7607c5bc-454a-496b-a034-d2a13871d26c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4874,)\n"
          ]
        }
      ],
      "source": [
        "lr = 0.5\n",
        "n_epochs = 10\n",
        "reg_const = 0.05\n",
        "\n",
        "softmax_MR = Softmax(n_class_MR, lr, n_epochs, reg_const)\n",
        "#rint(n_class_MR)\n",
        "softmax_MR.train(X_train_MR, y_train_MR)\n",
        "print(y_train_MR.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "Sg4W3La7-Msm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d315c4d9-5e8e-4bdc-b216-7c9c99456cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is given by: 95.219532\n"
          ]
        }
      ],
      "source": [
        "pred_softmax = softmax_MR.predict(X_train_MR)\n",
        "print('The training accuracy is given by: %f' % (get_acc(pred_softmax, y_train_MR)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn5Cplre-Msn"
      },
      "source": [
        "### Validate Softmax on Mushroom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "P5qu-q_m-Msn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0a7091ee-338a-4009-d0fb-484e4a5dd6df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy is given by: 94.523077\n"
          ]
        }
      ],
      "source": [
        "pred_softmax = softmax_MR.predict(X_val_MR)\n",
        "print('The validation accuracy is given by: %f' % (get_acc(pred_softmax, y_val_MR)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhfyBv1o-Mso"
      },
      "source": [
        "### Testing Softmax on Mushroom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "_O8kadXF-Mss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e21c2bdb-2f97-4f14-9322-1d4b46bcd847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The testing accuracy is given by: 95.323077\n"
          ]
        }
      ],
      "source": [
        "pred_softmax = softmax_MR.predict(X_test_MR)\n",
        "print('The testing accuracy is given by: %f' % (get_acc(pred_softmax, y_test_MR)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vohObqCa-Mst"
      },
      "source": [
        "# Logistic Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiyFjKF5-Mst"
      },
      "source": [
        "The Logistic Classifier has 2 hyperparameters that you can experiment with:\n",
        "- **Learning rate** - similar to as defined above in Perceptron, this parameter scales by how much the weights are changed according to the calculated gradient update. \n",
        "- **Number of Epochs** - As described for perceptron.\n",
        "- **Threshold** - The decision boundary of the classifier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTNSCFfP-Msu"
      },
      "source": [
        "You will implement the Logistic Classifier in the **models/logistic.py**\n",
        "\n",
        "\n",
        "The following code: \n",
        "- Creates an instance of the Logistic classifier class \n",
        "- The train function of the Logistic class is trained on the training data\n",
        "- We use the predict function to find the training accuracy as well as the testing accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etVoNlJR-Msu"
      },
      "source": [
        "### Training Logistic Classifer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "HEOvAeMTmskF"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load mushroom dataset"
      ],
      "metadata": {
        "id": "FoX_aG17sCgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING = 0.6 indicates 60% of the data is used as the training dataset.\n",
        "VALIDATION = 0.2\n",
        "data = get_MUSHROOM_data(VALIDATION)\n",
        "X_train_MR, y_train_MR = data['X_train'], data['y_train']\n",
        "X_val_MR, y_val_MR = data['X_val'], data['y_val']\n",
        "X_test_MR, y_test_MR = data['X_test'], data['y_test']\n",
        "n_class_MR = len(np.unique(y_test_MR))\n",
        "\n",
        "print(\"Number of train samples: \", X_train_MR.shape[0])\n",
        "print(\"Number of val samples: \", X_val_MR.shape[0])\n",
        "print(\"Number of test samples: \", X_test_MR.shape[0])"
      ],
      "metadata": {
        "id": "vQO6i0wqmsKD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "35fa64ba-7490-4143-ae6d-a4dd90dab3d6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train samples:  4874\n",
            "Number of val samples:  1625\n",
            "Number of test samples:  1625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "syjsspiq6TbZ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TAKE a look at the x_sub_i mushroom example values\n",
        "#TOTAL examples: 4874\n",
        "print(\"X_train_MR is: \", X_train_MR)\n",
        "\n",
        "# there are 22 features = dimensions of each mushroom example\n",
        "print(\"X_train_MR shape is: \", X_train_MR.shape)\n",
        "\n",
        "#see the training label values\n",
        "print(\"\\ny_train_MR is: \", y_train_MR)\n",
        "\n",
        "# see the shape of ytrain\n",
        "print(\"y_train_MR shape is: \", y_train_MR.shape)\n",
        "\n",
        "#################################################################\n",
        "#see the validation label values\n",
        "print(\"\\ny_val_MR is: \", y_val_MR)\n",
        "\n",
        "# see the shape of y for validation\n",
        "print(\"y_val_MR is: \", y_val_MR.shape)\n",
        "####################################################################\n",
        "\n",
        "\n",
        "#see the testing label values\n",
        "print(\"\\ny_test_MR is: \", y_test_MR)\n",
        "\n",
        "# see the shape of ytest\n",
        "print(\"y_test_MR is: \", y_test_MR.shape)\n",
        "\n",
        "# y_train_MR is:  [1 0 0 ... 1 1 0]\n",
        "# y_train_MR is:  (4874,)\n",
        "#we notice that y_train has 1,0 as labels. We need to replace the zero labels with -1.\n",
        "#convert the zero in y to -1.\n",
        "y_train_MR = np.array([-1 if value==0 else 1 for value in y_train_MR])\n",
        "print(\"\\n\\n\\nconverted_y_train is: \",y_train_MR)\n",
        "\n",
        "\n",
        "#convert for y_val_MR as well\n",
        "y_val_MR = np.array([-1 if value==0 else 1 for value in y_val_MR])\n",
        "print(\"\\nconverted_y_val_MR is: \",y_val_MR)\n",
        "\n",
        "#convert for y_test_MR as well\n",
        "y_test_MR = np.array([-1 if value==0 else 1 for value in y_test_MR])\n",
        "print(\"\\nconverted_y_test_MR is: \",y_test_MR)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g-PN1RjImrx6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0c1b35fa-7163-4ecc-c341-f11cfd7a1231"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_MR is:  [[5 0 8 ... 3 4 0]\n",
            " [5 0 4 ... 2 3 1]\n",
            " [5 2 8 ... 3 3 3]\n",
            " ...\n",
            " [3 3 4 ... 7 4 4]\n",
            " [2 0 3 ... 1 5 4]\n",
            " [5 3 2 ... 7 1 6]]\n",
            "X_train_MR shape is:  (4874, 22)\n",
            "\n",
            "y_train_MR is:  [1 0 0 ... 1 1 0]\n",
            "y_train_MR shape is:  (4874,)\n",
            "\n",
            "y_val_MR is:  [1 0 0 ... 0 0 0]\n",
            "y_val_MR is:  (1625,)\n",
            "\n",
            "y_test_MR is:  [0 0 0 ... 0 0 0]\n",
            "y_test_MR is:  (1625,)\n",
            "\n",
            "\n",
            "\n",
            "converted_y_train is:  [ 1 -1 -1 ...  1  1 -1]\n",
            "\n",
            "converted_y_val_MR is:  [ 1 -1 -1 ... -1 -1 -1]\n",
            "\n",
            "converted_y_test_MR is:  [-1 -1 -1 ... -1 -1 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scalar_value_of_sigmoid(sigmoid_input):\n",
        "        \"\"\"Sigmoid function.\n",
        "\n",
        "        Parameters:\n",
        "            z: the input\n",
        "\n",
        "        Returns:\n",
        "            the sigmoid of the input\n",
        "        \"\"\"\n",
        "        \n",
        "        sigmoid_value = 1/(1+math.exp(-1*sigmoid_input))\n",
        "        # print(\"sigmoid function returns: \",sigmoid_value)\n",
        "        return sigmoid_value"
      ],
      "metadata": {
        "id": "c0eUVcPu6X5C"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Qc-Ob4pjmrMX"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the gradient of loss at a point\n",
        "def sgd_gradient_of_loss_for_a_point(weight_vec,y_sub_i,x_sub_i,learning_rate,sigmoid_input,x_cols):\n",
        "\n",
        "\n",
        "  # print(\"y_sub_i is: \",y_sub_i)\n",
        "\n",
        "  sigmoid_input_for_gradient = -1*y_sub_i*(np.dot(x_sub_i,weight_vec))\n",
        "  # print(\"sigmoid input of gradient is: \",sigmoid_input_for_gradient)\n",
        "  # print(\"shape of sigmoid input of gradient is: \",sigmoid_input_for_gradient.shape)\n",
        "\n",
        "  # print(\"x_sub_i is: \",x_sub_i)\n",
        "  # print(\"x_sub_i shape is: \",x_sub_i.shape)\n",
        "\n",
        "  # print(\"weight_vec is: \",weight_vec)\n",
        "  # print(\"weight_vec shape is: \",weight_vec.shape)\n",
        "\n",
        "  output_of_sigmoid_function = scalar_value_of_sigmoid(sigmoid_input_for_gradient)\n",
        "  # print(\"output_of_sigmoid_function is: \",output_of_sigmoid_function)  \n",
        "\n",
        "\n",
        "  gradient_of_loss_multiplied_by_eta = (x_sub_i)*learning_rate*(output_of_sigmoid_function)*y_sub_i\n",
        "  # print(\"gradient_of_loss_multiplied_by_eta is: \",gradient_of_loss_multiplied_by_eta)\n",
        "  # print(\"shape of gradient_of_loss_multiplied_by_eta is: \",gradient_of_loss_multiplied_by_eta.shape)\n",
        "  gradient_of_loss_multiplied_by_eta = gradient_of_loss_multiplied_by_eta.reshape(x_cols,1)\n",
        "\n",
        "  return gradient_of_loss_multiplied_by_eta\n"
      ],
      "metadata": {
        "id": "XsFq86qkmd9E"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_acc(pred, y_test):\n",
        "    return np.sum(y_test == pred) / len(y_test) * 100\n"
      ],
      "metadata": {
        "id": "4SCCom_fmejH"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Logistic regression model.\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Logistic:\n",
        "    def __init__(self, lr: float, epochs: int, threshold: float):\n",
        "        \"\"\"Initialize a new classifier.\n",
        "\n",
        "        Parameters:\n",
        "            lr: the learning rate\n",
        "            epochs: the number of epochs to train for\n",
        "        \"\"\"\n",
        "        self.weight_vec = None  # TODO: change this\n",
        "        self.lr = lr\n",
        "        self.epoch_number = epochs\n",
        "        self.threshold = threshold\n",
        "        self.logistic_loss = []\n",
        "\n",
        "    # def sigmoid(self, z: np.ndarray) -> np.ndarray:\n",
        "    #     \"\"\"Sigmoid function.\n",
        "\n",
        "    #     Parameters:\n",
        "    #         z: the input\n",
        "\n",
        "    #     Returns:\n",
        "    #         the sigmoid of the input\n",
        "    #     \"\"\"\n",
        "    #     exp_z = np.exp(-z)\n",
        "    #     # print(\"exp_z is: \",exp_z)\n",
        "    #     # ones_array = np.ones(len(z))\n",
        "    #     sum = 1+exp_z \n",
        "    #     print(\"sum is: \",sum)\n",
        "    #     sigmoid_value = 1/(1+exp_z)\n",
        "    #     print(\"sigmoid function returns: \",sigmoid_value)\n",
        "    #     return sigmoid_value\n",
        "\n",
        "    def train(self, X_train: np.ndarray, y_train: np.ndarray):\n",
        "        \"\"\"Train the classifier.\n",
        "\n",
        "        Use the *logistic regression update rule* as introduced in lecture.\n",
        "\n",
        "        Parameters:\n",
        "            X_train: a numpy array of shape (N, D) containing training data;\n",
        "                N examples with D dimensions\n",
        "            y_train: a numpy array of shape (N,) containing training labels\n",
        "        \"\"\"\n",
        "        #in class notes, x_rows=n and x_cols=d\n",
        "        x_rows,x_cols = X_train.shape\n",
        "        self.weight_vec = np.zeros((x_cols,1))\n",
        "        # print(\"self.weight_vec is: \",self.weight_vec)\n",
        "        # print(\"self.weight_vec.shape is: \",self.weight_vec.shape)\n",
        "\n",
        "        #reshape y_train to a column vector that is n by 1, \n",
        "        y_train = y_train.reshape(x_rows,1)\n",
        "  \n",
        "\n",
        "        #loop for each epoch\n",
        "        for epoch_number in range(self.epoch_number):\n",
        "\n",
        "            #we need to iterate over the weight matrix and take each row as input\n",
        "            for x_row_index in range(x_rows):\n",
        "                  x_row_for_example = X_train[x_row_index]\n",
        "                  # print(\"x_row_for_example:\",x_row_for_example)\n",
        "                  y_label = y_train[x_row_index]\n",
        "                  # print(\"y_label:\",y_label)\n",
        "\n",
        "                  sigmoid_input = y_label*np.dot(x_row_for_example,self.weight_vec)\n",
        "                  sigmoid_output = scalar_value_of_sigmoid(sigmoid_input)\n",
        "                  delta_weight_vector = sgd_gradient_of_loss_for_a_point(self.weight_vec,y_label,x_row_for_example,self.lr,sigmoid_input,x_cols)\n",
        "                  # print(\"delta_weight_vector is: \",delta_weight_vector)\n",
        "                  \n",
        "                  # Updating the weight vector.\n",
        "                  # print(\"weight vector before update is: \",self.weight_vec)\n",
        "                  self.weight_vec = self.weight_vec + delta_weight_vector\n",
        "                  # print(\"weight vector after update is: \",self.weight_vec)\n",
        "              \n",
        "            \n",
        "        return self.weight_vec\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Use the trained weights to predict labels for test data points.\n",
        "\n",
        "        Parameters:\n",
        "            X_test: a numpy array of shape (N, D) containing testing data;\n",
        "                N examples with D dimensions\n",
        "\n",
        "        Returns:\n",
        "            predicted labels for the data in X_test; a 1-dimensional array of\n",
        "                length N, where each element is an integer giving the predicted\n",
        "                class.\n",
        "        \"\"\"\n",
        "\n",
        "        N, D = X_test.shape\n",
        "        labels = np.zeros((N))\n",
        "        #print(self.w.shape)\n",
        "        for example_num in range(N):\n",
        "          x = X_test[example_num]\n",
        "          y_hat = np.dot(x,self.weight_vec)\n",
        "          if y_hat>=self.threshold:\n",
        "            labels[example_num] = 1\n",
        "          else:\n",
        "            labels[example_num] = -1\n",
        "\n",
        "\n",
        "        return labels\n"
      ],
      "metadata": {
        "id": "ens317Rb6cPB"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.6\n",
        "n_epochs = 20\n",
        "threshold = 0.5\n",
        "\n",
        "lr = Logistic(learning_rate, n_epochs, threshold)\n",
        "lr.train(X_train_MR, y_train_MR)"
      ],
      "metadata": {
        "id": "nSdtZsfUezIw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "48848f95-0b43-4d89-caef-17405d19bb0e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  -2.01724437],\n",
              "       [  22.23359795],\n",
              "       [   1.65088044],\n",
              "       [ -12.09568461],\n",
              "       [ -14.47913435],\n",
              "       [  42.75131934],\n",
              "       [-178.24504802],\n",
              "       [ 262.5225279 ],\n",
              "       [  -5.72225053],\n",
              "       [ -22.68513477],\n",
              "       [ -68.93669088],\n",
              "       [-147.59746428],\n",
              "       [ -24.0227172 ],\n",
              "       [  -2.93313362],\n",
              "       [  -3.43449207],\n",
              "       [   0.        ],\n",
              "       [ 191.40812511],\n",
              "       [   1.70174918],\n",
              "       [  22.76219888],\n",
              "       [ -22.57656537],\n",
              "       [ -11.98547559],\n",
              "       [   3.82978282]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CqywDiu6evdA"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "yk_IVT7A-Msv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "32fe953c-1515-4e43-80dc-bf6de19bc8d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is given by: 94.870743\n",
            "True y labels for training set of mushroom dataset are: [ 1 -1 -1 ...  1  1 -1]\n",
            "Predicted y labels for training set of mushroom dataset are: [ 1. -1. -1. ...  1.  1. -1.]\n"
          ]
        }
      ],
      "source": [
        "pred_lr = lr.predict(X_train_MR)\n",
        "print('The training accuracy is given by: %f' % (get_acc(pred_lr, y_train_MR)))\n",
        "\n",
        "print(\"True y labels for training set of mushroom dataset are:\",y_train_MR)\n",
        "print(\"Predicted y labels for training set of mushroom dataset are:\",pred_lr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhQPXBrS-Msv"
      },
      "source": [
        "### Validate Logistic Classifer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "XXRpR85a-Msw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "21690d51-f29e-4e62-9e58-8efc0879c5e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy is given by: 94.153846\n"
          ]
        }
      ],
      "source": [
        "pred_lr = lr.predict(X_val_MR)\n",
        "print('The validation accuracy is given by: %f' % (get_acc(pred_lr, y_val_MR)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xk6Ojly-Msw"
      },
      "source": [
        "### Test Logistic Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "SQNrBlkw-Msx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4cce5c62-1bd8-4782-a6d1-99699f177bc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The testing accuracy is given by: 94.461538\n"
          ]
        }
      ],
      "source": [
        "pred_lr = lr.predict(X_test_MR)\n",
        "print('The testing accuracy is given by: %f' % (get_acc(pred_lr, y_test_MR)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVZHtqUV-Msx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "CS 444 Assignment-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}